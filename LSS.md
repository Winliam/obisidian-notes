[[BevFormer]]

##### Intro
​​2020年​​《Lift, Splat, Shoot: Encoding Images From Arbitrary Camera Rigs by Implicitly Unprojecting to 3D》论文在计算机视觉顶会（如ECCV/CVPR）发布，首次提出Lift-Splat-Shoot（LSS）框架，解决了多相机图像到鸟瞰图（BEV）的转换问题。

##### 流程简述
Lift
- 图像增强、backbone特征提取、多尺度特征图融合、深度概率&语义特征预测、语义特征向深度概率分布投影->8x22x41个64维特征向量A
- uv关键点选取、uvd组合创建、3D逆投影->8x22x41个关键点自车坐标系下的3d坐标B
Splat
- 3d坐标点与特征向量对齐绑定、BEV栅格投影、栅格内平均池化、Z方向最大池化->200x200x64 BEV特征
Shoot
- 目标检测（CenterPoint方案为例）：卷积强化、属性预测（多头1x1卷积）、类别概率阈值筛选有效目标、NMS去重
- 车道线检测：
	1. 栅格属性分割
	2. 关键点预测？不是太理解
	3. DETR范式，每个实例一个query，解码得到控制点坐标（多段线或者贝塞尔曲线）
	4. 自回归预测？具体如何操作？
##### 关键结论
- 算法的核心是：为每一个特征向量assign一个自车坐标系下的3d坐标。据此在自车坐标系下以抽象的特征向量的形式进行不同相机图像特征的融合
- 具体的做法是：
	- 特征向量与图像坐标系的对应关系是易得的，但是图像坐标系向世界坐标系的逆投影因为缺乏深度值是无法直接实现的
	- 所以这里预设一组离散的深度值，据此求得每个特征向量对应的uvd，进而实现逆投影
	- 并且在提取特征向量时，同时预测这个向量在预设深度值集合上的概率分布，进而得到向量在世界坐标系不同位置上的概率分布
	- 将世界坐标系下的感兴趣区域体素化，将同一个体素内所有的特征向量分量的均值作为这个体素处真实物理世界信息的特征向量表示，是为**BEV特征**
	- 后续的各项预测任务以BEV特征作为输入进行 
- 其他重要设计
	- 特征提取前先进行针对相机外参的图像增强：
		- 例子：同一 Batch 内，前摄像头图像可能旋转 5°，后摄像头图像平移 10 像素。
		- 作用：通过引入不可预测的扰动，强制模型学习 ​​几何不变的深度与特征表达​​，避免过拟合固定视角
	- 同时使用backbone提取的多尺度图层的特征，1x1卷对齐不同图层的通道数量，上采样高阶图层对齐HW尺寸，最后拼接在一起
	- CenterPoint目标预测方案中，真值向BEV栅格投影时，使用高斯核将中心点转换为一个分布
	- BEV栅格在Z轴上进行最大池化，以保留每个平面位置在垂直方向最显著的特征

##### 维度变化
- 原始图像：(B, N, 3, 900, 1600)
- 增强缩放后：	(B, N, 3, 128, 352)
- **EfficientNet-B0**特征提取&跨层融合：(B, N, 512, 8, 22)
	- C5: (B×N, 320, 4, 22) -> (B, N, 256, 4, 22) -> (B, N, 256, 8, 22)
	- C4: (B×N, 320, 8, 22) -> (B, N, 256, 8, 22)
	- 拼接：(B, N, 512, 8, 22)
	- 细化：(B, N, 256, 8, 22)
	- 升维：(B, N, 512, 8, 22)
- 语义特征&深度概率分布1x1卷积预测（语义64+深度41）：(B, N, 105, 8, 22)
- 语义特征按照深度概率拆分分量：(B, N, 64, 41, 8, 22)
- uvd集合逆投影：(B, N, 3, 41, 8, 22)
- BEV栅格投影与平均池化、最大池化：(B, 64, Z, 200, 200) -> (B, 64, 200, 200)
- CenterPoint目标检测：
	- 特征卷积强化： (B, 128, 200, 200)
	- 1x1卷积检测头：
		- 栅格类别概率：(B, C, 200, 200)
		- 3维尺寸：(B, Cx3, 200, 200)
	- 过滤类别概率小于阈值的点再NMS