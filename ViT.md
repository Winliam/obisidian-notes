[[Transformer]]

##### Intro
 ​​2020年​​ 由Google研究团队在论文 ​​《An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale》​​ 中提出，于 ​​2021年​​ 被国际学习表征会议（ICLR 2021）接收，用于图像分类。打破了CV领域长期依赖CNN的范式，为Transformer在多模态任务（如图像、视频、跨模态学习）中的应用铺平道路。
##### 流程简述
- 图像分块->卷积嵌入->叠加位置编码->添加全局分类向量->多头自注意力编码->MLP分类头
##### 关键结论
- 只使用了Transformer编码器部分，未使用解码器部分
- 位置编码向量和全局分类向量都是可学习参数
- 位置编码向量的维度是(14x14+1)x768
- 全局分类向量的维度是1x768

##### 概念解释
- 图像分块：将一张224x224x3的原始图像分割成14x14个16x16x3的patches

- 卷积嵌入：使用一个768通道的16x16卷积核，将每个patch处理成一个768维度的向量

- 叠加位置编码：为每一个patch对应的向量&全局分类向量叠加上各自对应的位置编码向量

- 添加全局分类向量：在所有嵌入向量最前方concat一个768维的向量，用来提取全局图像信息

- 多头自注意力编码：与Transformer一样，将各个patch的信息相互交联，汇总到全局分类向量

- MLP分类头：对经过编码器处理的全局分类向量进行MLP处理，映射回维度等于总类别数量的向量，经过softmax后得到分类概率




