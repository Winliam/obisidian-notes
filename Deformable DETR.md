[[Transformer]]
[[DETR]]
[[DCN]]

##### Intro
针对DETR的两个显著局限性：
1. 小目标检测差（因为没有设计类似FPN的多尺度）
2. 收敛慢（因为随机初始化的Queries缺乏位置先验）
2021年ICLR上提出 《Deformable DETR: Deformable Transformers for End-to-End Object Detection》

##### 关键结论
1. **保留Resnet backbone输出的多层特征图**，而不是DETR中的一层，并用256通道的1x1卷积调整到相同维度
2. 注意力组合稀疏化，Q只和一部分K做注意力计算，复杂度从N^2降低到N。具体有

#### 计算流程
###### 图像嵌入：
- 输入张量​​：images.shape = [batch_size, 3, H, W]（例如[1, 3, 800, 1066]）
- Backbone(ResNet)​​：输出多尺度特征图（C3, C4, C5, C6）
	C3.shape = [1, 512, 100, 133]（H/8, W/8）
	C4.shape = [1, 1024, 50, 67]（H/16, W/16）
	C5.shape = [1, 2048, 25, 34]（H/32, W/32）
	C6.shape = [1, 2048, 13, 17]（C5经stride=2卷积得到，H/64, W/64）
- 1×1卷积降维​​：统一通道数为256，输出：[1, 256, 100, 133], [1, 256, 50, 67], [1, 256, 25, 34], [1, 256, 13, 17], 合计17721个256维度的向量
- 叠加位置编码：使用二维正余弦编码每一个特征向量的二维空间位置，并叠加到特征向量中，维度不变
- 尺度编码：用一个可学习的向量表征尺度，不同的尺度特征图上叠加上不同的向量，用来编码尺度信息

###### 多头可变形自注意力编码（8头，4采样点为例）
1. 特征图统一V投影&通道切分：用一个256x256的线性层，对嵌入特征矩阵进行投影，视作V矩阵，并且沿256这个通道为每个头做均等切分，得到17721x8x32的V张量
2. 偏移量&权重预测：在每个头内，用一个256x(4x2+4)的线性层，对每一个特征向量进行映射，得到的维度为(4x2+4)的向量被解析为XY方向上的4x2个偏移量数值，和对应向量的4个权重值
3. 索引V向量：使用4x2个偏移量数值，以当前特征向量在其所在尺度的特征图中的空间位置为出发点，插值得到对应的V向量（注意通道切分），得到4个32维的V向量
4. 加权平均：使用Step2中得到的4个权重值和Step3中的4个32维向量，做加权平均，得到一个32维的加权平均V向量
5. 多头拼接：将8个头的加权平均V向量拼接在一起，维度恢复到256。加一个256x256线性层消除“拼接缝隙”

###### 多头可变形交叉注意力解码（8头，4采样点为例）
整体流程类似编码部分，需要注意的地方有：
1. 仿照DETR，预设200个256维度的向量作为Query
2. 在编码器中，每个特征向量天然具有其在同尺度图层中的二维空间位置索引，所以在查找应该跟哪些特征向量做注意力时，基准位置是已知的。但是对于解码过程，Query向量是预设的，没有空间位置。因此需要用一个256x2的线性层来预测每个query对应的基准点位置, 以此来结合预测得到的偏移量来找到对应的v向量。
3. 并且基准点的预测只在第一层注意力单元做，后续在基准点的基础上不断累加各层的偏移量即可。
4. 另外，这里只预测了基准点的2维坐标，但是编码器产生每一个特征向量除了XY空间位置之外，还多了一个表征在哪个尺度图层的维度。原论文的解决方式是，对每一个图层都分配4个采样点。因此，对于解码器部分，偏移量&权重预测这一步，线性层的尺寸是256x((4x2+4)x4)，而且这里每个v向量的权重值包含了尺度权重的含义

###### 预测
同DETR，用两个MLP作为预测头+坐标预测头来处理解码器输出的200x256 tensor。损失函数的设计仍参考DETR。




